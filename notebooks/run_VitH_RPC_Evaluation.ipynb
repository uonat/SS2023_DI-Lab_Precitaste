{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtPKf_hkPd8u",
        "outputId": "36a67ece-45dc-4a74-f370-ebba76d48438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'SS2023_DI-Lab_Precitaste'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
            "remote: Total 169 (delta 34), reused 147 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (169/169), 16.12 MiB | 16.40 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/uonat/SS2023_DI-Lab_Precitaste.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr9VGLGpPr91"
      },
      "outputs": [],
      "source": [
        "# Copy script to main directory to not dealing with directory issues\n",
        "!cp '/content/SS2023_DI-Lab_Precitaste/scripts/download_rpc.sh' 'download_rpc.sh'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XXNX65uCPzW7"
      },
      "source": [
        "Upload kaggle.json file to runtime in contents folder before running below line.\n",
        "\n",
        "To generate that json head to your account page and Account tab on that page: https://www.kaggle.com/settings/account. Then, click \"Create New Token\" button to download your own kaggle.json file. This is specific for user account. Upload the json file to the runtime and run below cell to move the file to the required folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c7UyGa4PwSO",
        "outputId": "4772d67b-9d4f-4ef1-cced-e7e9bd9ef545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading dataset!\n",
            "Downloading retail-product-checkout-dataset.zip to /content\n",
            " 62% 15.6G/25.3G [14:00<08:44, 19.9MB/s]\n",
            "User cancelled operation\n",
            "Unzipping dataset...\n",
            "[retail-product-checkout-dataset.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of retail-product-checkout-dataset.zip or\n",
            "        retail-product-checkout-dataset.zip.zip, and cannot find retail-product-checkout-dataset.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "# For quicker experiment with only validation set, change\n",
        "# unzip retail-product-checkout-dataset.zip line to\n",
        "# unzip retail-product-checkout-dataset.zip val2019/*\n",
        "# This will only unzip validation set\n",
        "!bash ./download_rpc.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lerYgrxcPeS7"
      },
      "outputs": [],
      "source": [
        "%cd SS2023_DI-Lab_Precitaste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEIc8xaXPf_c"
      },
      "outputs": [],
      "source": [
        "!pip install . &> /dev/null"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CLOyEN85FTaX"
      },
      "source": [
        "Setup for ViT-H model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9n0Gb1ZPhO9"
      },
      "outputs": [],
      "source": [
        "# This cell sets ViT-H model\n",
        "\n",
        "import distutils.core\n",
        "import sys,os\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'  &> /dev/null\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])} &> /dev/null\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "!wget 'https://dl.fbaipublicfiles.com/detectron2/ViTDet/LVIS/mask_rcnn_vitdet_h/332434656/model_final_866730.pkl'\n",
        "\n",
        "from models.VitDet import load_model,Draw_pred_BB,Draw_original_seg\n",
        "\n",
        "model_path =\"/content/SS2023_DI-Lab_Precitaste/model_final_866730.pkl\"\n",
        "config_path = \"/content/SS2023_DI-Lab_Precitaste/detectron2/projects/ViTDet/configs/LVIS/mask_rcnn_vitdet_h_100ep.py\"\n",
        "model = load_model(model_path,config_path) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gHJC8e4cai6"
      },
      "outputs": [],
      "source": [
        "from dataset.RPCDataset import RPCDataset\n",
        "\n",
        "val_dataset_path = \"/content/retail_product_checkout\"\n",
        "val_dataset = RPCDataset(val_dataset_path, \"val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bih8MFurSAV7",
        "outputId": "fd7ee721-6391-4d56-b6c1-ee40b99b8774"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def Draw_pred_BB(img, model_result):\n",
        "    final_img = img.copy()\n",
        "    for row_index in range(len(model_result[0][\"instances\"])):\n",
        "        if model_result[0][\"instances\"].scores[row_index] > 0.4:\n",
        "            x1,y1,x2,y2 = model_result[0][\"instances\"].pred_boxes[row_index].tensor.int().tolist()[0]\n",
        "            cv2.rectangle(final_img, (x1*4, y1*4), (x2*4, y2*4), (43, 123, 255), 5)\n",
        "    return final_img\n",
        "\n",
        "def Draw_pred_BB_editted(img,p_b,p_s):\n",
        "    final_img = img.copy()\n",
        "    for row_index in range(len(p_b)):\n",
        "        if p_s[row_index] > 0.5:\n",
        "            x1,y1,x2,y2 = p_b[row_index]\n",
        "            cv2.rectangle(final_img, (x1*4, y1*4), (x2*4, y2*4), (43, 123, 255), 5)\n",
        "    return final_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from random import randint\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from utilities.non_maximum_suppression import nms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "rand_idx = randint(0, val_dataset.get_num_imgs()-1)\n",
        "\n",
        "img_path = val_dataset.get_img_path_by_id(rand_idx)\n",
        "\n",
        "pil_img = Image.open(img_path)\n",
        "\n",
        "h,w = pil_img.size\n",
        "img = transforms.PILToTensor()(pil_img.convert(\"RGB\"))\n",
        "resized_img = transforms.Resize((int(h/4), int(w/4)), antialias=None)(img)    \n",
        "batch = [{'image':resized_img.to(device)}]\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    model_result=model(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bbox_img = Draw_pred_BB(np.array(pil_img), model_result)\n",
        "plt.figure()\n",
        "plt.imshow(bbox_img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utilities.non_maximum_suppression import run_nms \n",
        "\n",
        "picked_boxes, picked_score = run_nms(\n",
        "    model_result[0]['instances'].pred_boxes.tensor.to(torch.int).tolist(),\n",
        "    model_result[0]['instances'].scores.tolist(),\n",
        "    np.asarray(img),\n",
        "    0.5\n",
        ")\n",
        "nms_drawn_img = Draw_pred_BB_editted(np.array(pil_img), picked_boxes, picked_score)\n",
        "plt.figure()\n",
        "plt.imshow(nms_drawn_img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXivw9oth0Vn"
      },
      "outputs": [],
      "source": [
        "pred_txt_path = \"/content/rpc-val-preds\"\n",
        "os.makedirs(pred_txt_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDugntJPcUKU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "from utilities.non_maximum_suppression import nms \n",
        "from random import randint\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import random \n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# Using cpu is just for testing, code works with gpu too. \n",
        "# Might need some modifications on the code\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "\n",
        "for i in range(val_dataset.get_num_imgs()):\n",
        "  img_path = val_dataset.get_img_path_by_id(i)\n",
        "\n",
        "  pil_img = Image.open(img_path)\n",
        "  h,w = pil_img.size\n",
        "  img = transforms.PILToTensor()(pil_img.convert(\"RGB\"))\n",
        "  resized_img = transforms.Resize((int(h/4), int(w/4)), antialias=None)(img)    \n",
        "  batch = [{'image':resized_img.to(device)}]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model_result=model(batch)\n",
        "\n",
        "  picked_boxes, picked_score = nms(\n",
        "      model_result[0]['instances'].pred_boxes.tensor.to(torch.int).tolist(),\n",
        "      model_result[0]['instances'].scores.tolist(),\n",
        "      0.5)\n",
        "\n",
        "  pred_img_name = val_dataset.img_info[i]['file_name']\n",
        "  pred_txt_name = \"\".join(pred_img_name.split('.')[:-1]) + \".txt\"\n",
        "  pred_txt_path = os.path.join(pred_txt_path, pred_txt_name)\n",
        "\n",
        "  with open(pred_txt_path, \"w\") as txtfile:\n",
        "    for i,box in enumerate(picked_boxes):    \n",
        "      conf = picked_score[i]\n",
        "      \n",
        "      if conf < 0.2:\n",
        "          continue\n",
        "      # Rescale bounding boxes to original dim\n",
        "      x1, y1, x2, y2 = np.array(box) * 4\n",
        "      w = x2 - x1\n",
        "      h = y2 - y1\n",
        "      # Above calculation of w, h can change from model to model\n",
        "      # ViT-H outputs x1y1x2y2 but we need w and h\n",
        "      txtfile.write(\"object {} {} {} {} {}\\n\".format(conf, x1, y1, w, h))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
